# -*- coding: utf-8 -*-
"""cnn_logical.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12-E8SNKyhU0dsanyCcNqsv5Lxqww8ykV
"""

import os
import torch
import argparse
import numpy as np
import pandas as pd
import seaborn as sns
import torch.nn as nn
import dataset_utility
import torch.optim as optim
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader

class args:
    model = "CNN_Logical"
    epochs = 300
    batch_size = 32
    seed = 12345
    dataset = "iRaven"
    device = 1
    load_workers = 16
    resume = False
    path = "/content/drive/MyDrive/CS535Project/Dataset"
    save = "/content/drive/MyDrive/CS535Project/Dataset"
    img_size = 80
    lr = 1e-4
    beta1 = 0.9
    beta2 = 0.999
    epsilon = 1e-8
    meta_alpha = 0.0
    meta_beta = 0.0
    cuda = torch.cuda.is_available()

args.cuda = torch.cuda.is_available()
if args.cuda:
    torch.cuda.set_device(args.device)

data_path = "/content/drive/MyDrive/CS535Project/Dataset"

train = dataset(
    data_path,
    "train",
    args.img_size,
    transform=transforms.Compose([dataset_utility.ToTensor()]),
    shuffle=True,
    rotate=False,
    vertical_flip=False,
    vertical_roll=False,
    horizontal_flip=False,
    horizontal_roll=False,
    max_rotate_angle=180,
)
valid = dataset_utility(
    data_path,
    "val",
    args.img_size,
    transform=transforms.Compose([dataset_utility.ToTensor()]),
)
test = dataset_utility(
    data_path,
    "test",
    args.img_size,
    transform=transforms.Compose([dataset_utility.ToTensor()]),
)

trainloader = DataLoader(
    train, batch_size=args.batch_size, shuffle=True, num_workers=16
)
validloader = DataLoader(
    valid, batch_size=args.batch_size, shuffle=False, num_workers=16
)
testloader = DataLoader(test, batch_size=args.batch_size, shuffle=False, num_workers=16)

model = logical_cnn_arch(args)

if args.resume:
    model.load_model(args.save, 0)
if args.cuda:
    model = model.cuda()

import os
import numpy as np
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
import dataset_utility
import pandas as pd
import seaborn as sns

def train(epoch):
    model.train()
    train_loss = 0
    accuracy = 0
    loss_all = 0.0
    acc_all = 0.0
    counter = 0
    for batch_idx, (image, target, met_tar) in enumerate(trainloader):
        counter += 1
        if args.cuda:
            image = image.cuda()
            target = target.cuda()
            met_tar = met_tar.cuda()
        loss, acc = model.model_train(image, target, met_tar)
        loss_all += loss
        acc_all += acc
    if counter > 0:
        print("Training Loss:".format(loss_all / float(counter)))
    return loss_all / float(counter), acc_all / float(counter)


def validate(epoch):
    model.eval()
    val_loss = 0
    accuracy = 0
    loss_all = 0.0
    acc_all = 0.0
    counter = 0
    for batch_idx, (image, target, met_tar) in enumerate(validloader):
        counter += 1
        if args.cuda:
            image = image.cuda()
            target = target.cuda()
            met_tar = met_tar.cuda()
        loss, acc = model.model_validate(image, target, met_tar)
        loss_all += loss
        acc_all += acc
    if counter > 0:
        print(
            "Validation Loss: , Acc: ".format(
                loss_all / float(counter), acc_all / float(counter)
            )
        )
    return loss_all / float(counter), acc_all / float(counter)


def test(epoch):
    model.eval()
    accuracy = 0
    acc_all = 0.0
    counter = 0
    for batch_idx, (image, target, met_tar) in enumerate(testloader):
        counter += 1
        if args.cuda:
            image = image.cuda()
            target = target.cuda()
            met_tar = met_tar.cuda()
        acc = model.model_test(image, target, met_tar)
        acc_all += acc
    if counter > 0:
        print("Testing Acc:".format(acc_all / float(counter)))
    return acc_all / float(counter)

eps ,l_train, l_test, l_val, l_Acc, acc_test = [],[],[],[],[],[]

for epoch in range(0, args.epochs):
    train_loss, train_acc = train(epoch)
    val_loss, val_acc = validate(epoch)
    test_acc = test(epoch)
    eps.append(epoch)
    l_train.append(train_loss)
    l_test.append(train_acc)
    l_val.append(val_loss)
    l_Acc.append(val_acc)
    acc_test.append(test_acc)
    model.save_model(args.save, epoch, val_acc, val_loss)

training_stats = pd.DataFrame(
    {
        "epoch": epoch_lst,
        "training_loss": train_loss_lst,
        "training_accuracy": train_acc_lst,
        "validation_loss": val_loss_lst,
        "validation_accuracy": val_acc_lst,
        "test_accuracy": test_acc_lst,
    }
)

training_stats = training_stats.set_index("epoch")
sns.set(rc={"figure.figsize": (15, 8)})
sns.lineplot(data=training_stats[["training_loss", "validation_loss"]])